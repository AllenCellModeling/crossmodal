_aux_:
  _: &input1 "image"
  _: &input2 "rna"
  _: &latent_dim 10
  _: &in_channels 1
  _: &hidden_channels 4
  _: &kernel_size 3
  _: &stride 1
  _: &input_dims [36, 72, 91]
  _: &conv_block
    _target_: torch.nn.Sequential
    _args_:
      - _target_: torch.nn.LazyConv3d
        out_channels: *hidden_channels
        kernel_size: *kernel_size
        stride: 1
      - _target_: torch.nn.LeakyReLU
      - _target_: torch.nn.LazyBatchNorm3d
  _: &encoder_conv
    _target_: torch.nn.Sequential
    _args_:
      - *conv_block
      - *conv_block
      - *conv_block

_target_: crossmodal.models.CrossModalVAE
latent_dim: [128]
x_labels: [*input1, *input2]
class_labels: []
image_dims: 
rna_dims: 
x_dims: [${image_dims}, {rna_dims}]
encoder:
  *input1:
    _target_: torch.nn.Sequential
    _args_:
      - *encoder_conv
      - _target_: serotiny.networks.layers.Flatten
      - _target_: torch.nn.LazyLinear
        out_features: *latent_dim
  *input2: 
    _target_: serotiny.networks.MLP
    scale_output: 1
    hidden_layers: [256, 256]
    _args_: 
    - ${rna_dims}
    - ${latent_dim}

decoder:
  *input1:
      _target_: serotiny.networks.vae.ImageDecoder
      encoder: *encoder_conv
      input_dims: *input_dims
      in_channels: *in_channels
      latent_dim: *latent_dim
  *input2: 
    _target_: serotiny.networks.MLP
    scale_output: 1
    hidden_layers: [256, 256]
    _args_: 
    - ${latent_dim}
    - ${rna_dims}

reconstruction_loss:
  *input1:
    _target_: torch.nn.MSELoss
    reduction: 'mean'
  *input2:
    _target_: torch.nn.MSELoss
    reduction: 'mean'

latent_loss:
  *input1:
    net1: # for cell cycle classification
      _target_: serotiny.losses.AdversarialLoss
      discriminator:
        _target_: serotiny.networks.MLP
        hidden_layers: [10]
        _args_: 
        - ${model.latent_dim}
        - 9
      loss:
        _target_: torch.nn.CELoss
      argmax: True
    net2: # for predicting image or RNA
      _target_: serotiny.losses.AdversarialLoss
      discriminator:
        _target_: serotiny.networks.MLP
        hidden_layers: [64]
        _args_: 
        - ${model.latent_dim}
        - 1
      loss:
        _target_: torch.nn.BCELoss
  *input2:
    net1:
      _target_: serotiny.losses.AdversarialLoss
      discriminator:
        _target_: serotiny.networks.MLP
        hidden_layers: [10]
        _args_: 
        - ${model.latent_dim}
        - 9
      loss:
        _target_: torch.nn.CELoss
      argmax: True
    net2:
      _target_: serotiny.losses.AdversarialLoss
      discriminator:
        _target_: serotiny.networks.MLP
        hidden_layers: [64]
        _args_: 
        - ${model.latent_dim}
        - 1
      loss:
        _target_: torch.nn.BCELoss

prior:
  *input1: 
    net1:
      _target_: serotiny.models.vae.priors.IsotropicGaussianPrior
      dimensionality: ${model.latent_dim}
  *input2: 
    net2:
      _target_: serotiny.models.vae.priors.IsotropicGaussianPrior
      dimensionality: ${model.latent_dim}

latent_loss_weights:
  *input1: [1,1,1,1,1]
  *input2: [1,1,1,1,1]

latent_loss_target:
  *input1:
    net1: ${data.loaders.class}
    net2: [1, 1, 1, 1, 0]
  *input2:
    net1: ${data.loaders.class}
    net2: [0, 0, 0, 0, 0]

latent_loss_backprop_when: # when to optimize each subnetwork
  *input1: 
    net1: 1
    net2: 1
  *input2: 
    net1: 1
    net2: 1

latent_loss_optimizer: 
  adv:
    keys: [*input1, *input2]
    opt:
      _partial_: true
      _target_: torch.optim.adam.Adam
      lr: 0.001

latent_loss_scheduler: 
  adv:
    _partial_: true
    _target_: torch.optim.lr_scheduler.StepLR
    step_size: 45

optimizer: 
  main:
    keys: [*input1, *input2]
    opt:
      _partial_: true
      _target_: torch.optim.Adam
      lr: 1e-3

lr_scheduler:
  main:
    _partial_: true
    _target_: torch.optim.lr_scheduler.StepLR
    step_size: 45


